# CS25-Transformers-United

斯坦福CS25 Transformer United 课程

20220711 the project starts

## 课程介绍

### 主页

https://web.stanford.edu/class/cs25/

自 2017 年推出以来，Transformer 彻底改变了自然语言处理 (NLP)。现在，Transformer在深度学习中有了更多的应用场景，无论是计算机视觉 (CV)、强化学习 (RL)、生成对抗网络 (GAN)
、语音甚至是生物学。除其他外，Transformer 还能够创建强大的语言模型（如 GPT-3），并在 DeepMind 最近的 AlphaFold2 中发挥了重要作用，该算法解决了蛋白质折叠问题。

在本次研讨会中，我们将详细了解Transformer的工作原理，并深入探讨不同种类的Transformer及其在不同领域的应用。
我们通过讲师讲座、客座讲座和课堂讨论相结合来做到这一点。我们将邀请不同领域的Transformer研究前沿人士进行客座讲座。

### 课程知识要求

深度学习基础（必须理解attention机制）

或者学过

CS224N http://web.stanford.edu/class/cs224n/

CS231N http://cs231n.stanford.edu/

CS230 https://cs230.stanford.edu/

### 老师介绍

Instructors

Div Garg    https://divyanshgarg.com/

Chetanya Rastogi https://www.linkedin.com/in/chetanyarastogi/

Advay Pal https://advaypal.com/

Faculty Advisor

Chris Manning   https://nlp.stanford.edu/~manning/

## 内容

本课程的大部分内容将包括来自研究人员的演讲，他们讨论Transformer的最新突破，并解释他们如何将它们应用于他们的研究领域。 该课程的目标是汇集来自 ML、NLP、CV、生物学和其他社区关于Transformer的想法，
了解它们的广泛影响，并激发交叉合作研究。

## 课表

第一课
[youtube链接](https://www.youtube.com/watch?v=P127jhj-8-Y)
[字幕链接](https://github.com/wingwong0015/CS25-Transformers-United/blob/main/Videos/CS25_I_Stanford_Seminar_Transformers_United_DL_Models_that%20have_revolutionized_NLP_CV_%20RL.srt)



